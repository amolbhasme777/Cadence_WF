{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('JiraTicket_All_Stopword_Data_Removed_up_26-3-20.xlsx',sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15628 entries, 0 to 15627\n",
      "Data columns (total 9 columns):\n",
      "Issue_key          15628 non-null object\n",
      "Issue Type         15628 non-null object\n",
      "Office Location    9517 non-null object\n",
      "Pool               15628 non-null object\n",
      "Service            15628 non-null object\n",
      "Category           15628 non-null object\n",
      "Summary            14853 non-null object\n",
      "Description        15628 non-null object\n",
      "Description1       15460 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Description1'],inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Service Request    8743\n",
       "Incident           6717\n",
       "Name: Issue Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Issue Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15460 entries, 0 to 15459\n",
      "Data columns (total 9 columns):\n",
      "Issue_key          15460 non-null object\n",
      "Issue Type         15460 non-null object\n",
      "Office Location    9442 non-null object\n",
      "Pool               15460 non-null object\n",
      "Service            15460 non-null object\n",
      "Category           15460 non-null object\n",
      "Summary            14689 non-null object\n",
      "Description        15460 non-null object\n",
      "Description1       15460 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_key</th>\n",
       "      <th>Issue Type</th>\n",
       "      <th>Office Location</th>\n",
       "      <th>Pool</th>\n",
       "      <th>Service</th>\n",
       "      <th>Category</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Description1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT-18397</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>sj-techstop</td>\n",
       "      <td>Personal Computing Hardware</td>\n",
       "      <td>Recover Hardware Assets</td>\n",
       "      <td>IT ticket to recover the hardware assets-vpu...</td>\n",
       "      <td>IT ticket to recover the hardware assets-vpuch...</td>\n",
       "      <td>ticket recover hardware assets vpuchin pc pc v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT-14182</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>Bangalore, India</td>\n",
       "      <td>India-pool</td>\n",
       "      <td>Personal Computing Hardware</td>\n",
       "      <td>New PC</td>\n",
       "      <td>3 of 5 - Please deploy Precision 3630 Tower C...</td>\n",
       "      <td>3 of 5 - Please deploy Precision 3630 Tower CT...</td>\n",
       "      <td>deploy precision tower cto base serial gybz as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT-37239</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>Petah Tikva, Israel</td>\n",
       "      <td>L2-Servicedesk</td>\n",
       "      <td>Vormetric</td>\n",
       "      <td>Vormetric Policy - Grant Access</td>\n",
       "      <td>access to ARM ASHBROOK</td>\n",
       "      <td>+underlined text+i need permission to acces AR...</td>\n",
       "      <td>underlined text need permission acces arm ashb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT-12754</td>\n",
       "      <td>Incident</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>L2-Servicedesk</td>\n",
       "      <td>UNIX</td>\n",
       "      <td>VNC/NX issues</td>\n",
       "      <td>can't access certain file paths from my vnc</td>\n",
       "      <td>I can't access certain file paths from my vnc....</td>\n",
       "      <td>access certain file paths vnc icd check assist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT-8901</td>\n",
       "      <td>Service Request</td>\n",
       "      <td>Noida</td>\n",
       "      <td>L2-Servicedesk</td>\n",
       "      <td>Hosting-Storage</td>\n",
       "      <td>Storage- Create Home directory</td>\n",
       "      <td>create a directory named \"wangd\" under /grid/...</td>\n",
       "      <td>Please help to create a directory named \"wangd...</td>\n",
       "      <td>help create directory named wangd grid tfo scr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Issue_key       Issue Type      Office Location            Pool  \\\n",
       "0  IT-18397  Service Request         San Jose, CA     sj-techstop   \n",
       "1  IT-14182  Service Request     Bangalore, India      India-pool   \n",
       "2  IT-37239  Service Request  Petah Tikva, Israel  L2-Servicedesk   \n",
       "3  IT-12754         Incident         San Jose, CA  L2-Servicedesk   \n",
       "4   IT-8901  Service Request                Noida  L2-Servicedesk   \n",
       "\n",
       "                       Service                         Category  \\\n",
       "0  Personal Computing Hardware          Recover Hardware Assets   \n",
       "1  Personal Computing Hardware                           New PC   \n",
       "2                    Vormetric  Vormetric Policy - Grant Access   \n",
       "3                         UNIX                    VNC/NX issues   \n",
       "4              Hosting-Storage   Storage- Create Home directory   \n",
       "\n",
       "                                             Summary  \\\n",
       "0    IT ticket to recover the hardware assets-vpu...   \n",
       "1   3 of 5 - Please deploy Precision 3630 Tower C...   \n",
       "2                             access to ARM ASHBROOK   \n",
       "3        can't access certain file paths from my vnc   \n",
       "4   create a directory named \"wangd\" under /grid/...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  IT ticket to recover the hardware assets-vpuch...   \n",
       "1  3 of 5 - Please deploy Precision 3630 Tower CT...   \n",
       "2  +underlined text+i need permission to acces AR...   \n",
       "3  I can't access certain file paths from my vnc....   \n",
       "4  Please help to create a directory named \"wangd...   \n",
       "\n",
       "                                        Description1  \n",
       "0  ticket recover hardware assets vpuchin pc pc v...  \n",
       "1  deploy precision tower cto base serial gybz as...  \n",
       "2  underlined text need permission acces arm ashb...  \n",
       "3     access certain file paths vnc icd check assist  \n",
       "4  help create directory named wangd grid tfo scr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(ngram_range=(1,2))),  # strings to token integer counts\n",
    "        ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "        #('Normalize', preprocessing.Normalizer()),\n",
    "        ('c',LinearSVC()),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(df['Description1'], df['Issue Type'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, b_train, b_test =  train_test_split(df['Description'], df['Issue Type'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "pred=pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(ngram_range=(1,2))),  # strings to token integer counts\n",
    "        ('tfidf', TfidfTransformer()),  # inte/ger counts to weighted TF-IDF scores\n",
    "        #('Normalize', preprocessing.Normalizer()),\n",
    "        ('c',svm.SVC(kernel='linear',probability=True)),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(df['Description1'], df['Issue Type'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df[\"Description1\"]\n",
    "y_train=df[\"Issue Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_...ar', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1324   63]\n",
      " [  83 1622]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Incident       0.94      0.95      0.95      1387\n",
      "Service Request       0.96      0.95      0.96      1705\n",
      "\n",
      "      micro avg       0.95      0.95      0.95      3092\n",
      "      macro avg       0.95      0.95      0.95      3092\n",
      "   weighted avg       0.95      0.95      0.95      3092\n",
      "\n",
      "Accuracy :  0.9527813712807245\n"
     ]
    }
   ],
   "source": [
    "pred=pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(ngram_range=(1,2))),  # strings to token integer counts\n",
    "        ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "        #('Normalize', preprocessing.Normalizer()),\n",
    "        ('c',LogisticRegression()),  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(df['Description1'], df['Issue Type'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred=pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline,open('./Ticket_Type/All_SVM_Model_23_3-20.psm','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Description']=A_train\n",
    "# df[\"Description1\"]=X_train\n",
    "# df[\"Issue Type\"]=y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Description']=A_test\n",
    "# df[\"Description1\"]=X_test\n",
    "# df[\"Issue Type\"]=y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('Special_Stop_TestDataAE.xlsx')\n",
    "# df.to_excel(writer,\"Sheet1\",index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testData=pd.read_excel(\"ResultTestAE_special_stop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testData[\"Result\"] = testData[\"Issue Type\"] == testData[\"Prediction_Ticket_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(testData[testData[\"Result\"] == True])/len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = pd.ExcelWriter('TestDataAE_special_stop_TF.xlsx')\n",
    "# testData.to_excel(writer,\"Sheet1\",index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob =pipeline.predict_proba(X_test)\n",
    "\n",
    "#Convert to list\n",
    "y_list = y_test.values.tolist()\n",
    "X_list = X_test.values.tolist()\n",
    "A_list = A_test.values.tolist()\n",
    "\n",
    "prob = prob.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = [max(prob[i]) for i in range(len(prob))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'Prediction_Issue_Type': pred,'Actual_Issue_Type':y_list,'Original_Description':A_list,'Clean_Description':X_test,\"Confidence\":conf}\n",
    "y_df = pd.DataFrame(d)\n",
    "y_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df[\"Result\"] = y_df[\"Actual_Issue_Type\"] == y_df[\"Prediction_Issue_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./Ticket_Type/TTS_Results_Issue_Type.xlsx')\n",
    "y_df.to_excel(writer,\"Sheet1\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_df[y_df[\"Result\"] == True])/len(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abovecf = y_df[y_df[\"Confidence\"] >=0.1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abovecf[abovecf[\"Result\"] == True])/len(abovecf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrecords = []\n",
    "truerecords = []\n",
    "falserecords = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    i = i * 0.10\n",
    "    abovecf = y_df[y_df[\"Confidence\"] >= i].copy()\n",
    "    allrecords.append(len(abovecf))\n",
    "    truerecords.append(len(abovecf[abovecf[\"Result\"] == True]))\n",
    "    falserecords.append(len(abovecf[abovecf[\"Result\"] == False]))\n",
    "    accuracy.append(len(abovecf[abovecf[\"Result\"] == True])/len(abovecf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Tickets count above confidence Threshold': allrecords,'Correctly predicted tickets': truerecords, 'Incorrectly  predicted tickets': falserecords ,'Accuracy after Threshhold':accuracy,'Threeshold' : [x * 0.1 for x in range(0, 10)]}\n",
    "conf_data = pd.DataFrame(d)\n",
    "conf_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_data[\"Overall Tickets for Testing\"] = len(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_data[\"Tickets count routed  to manual Queue\"] =conf_data[\"Overall Tickets for Testing\"] - conf_data[\"Tickets count above confidence Threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./Ticket_Type/TTS_Result_confidence.xlsx')\n",
    "conf_data.to_excel(writer,\"Sheet1\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"./Ticket_Type/TTS_Classification_Report.xls\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.writelines([cr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(cm ,index=pipeline.classes_,columns=pipeline.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_excel(\"./Ticket_Type/TTS_Confusion_matrix.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plugin Result on seperate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_excel(\"./TestData/ResultTestAE_special_stop_Result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata[\"Result\"] = testdata[\"Issue Type\"] == testdata[\"Prediction_Ticket_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testdata[testdata[\"Result\"] == True])/len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./TestData/Results_Ticket_Type.xlsx')\n",
    "testdata.to_excel(writer,\"Sheet1\", index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abovecf = testdata[testdata[\"Prediction_Ticket_Type_confidence\"] >=0.1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abovecf[abovecf[\"Result\"] == True])/len(abovecf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrecords = []\n",
    "truerecords = []\n",
    "falserecords = []\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    i = i * 0.10\n",
    "    abovecf = testdata[testdata[\"Prediction_Ticket_Type_confidence\"] >= i].copy()\n",
    "    allrecords.append(len(abovecf))\n",
    "    truerecords.append(len(abovecf[abovecf[\"Result\"] == True]))\n",
    "    falserecords.append(len(abovecf[abovecf[\"Result\"] == False]))\n",
    "    accuracy.append(len(abovecf[abovecf[\"Result\"] == True])/len(abovecf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Tickets count above confidence Threshold': allrecords,'Correctly predicted tickets': truerecords, 'Incorrectly  predicted tickets': falserecords ,'Accuracy after Threshhold':accuracy,'Threeshold' : [x * 0.1 for x in range(0, 10)]}\n",
    "conf_data = pd.DataFrame(d)\n",
    "conf_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_data[\"Overall Tickets for Testing\"] = len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_data[\"Tickets count routed  to manual Queue\"] =conf_data[\"Overall Tickets for Testing\"] - conf_data[\"Tickets count above confidence Threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./TestData/Result_confidence.xlsx')\n",
    "conf_data.to_excel(writer,\"Sheet1\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('RandomTestData.xlsx')\n",
    "df.to_excel(writer,\"Sheet1\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
